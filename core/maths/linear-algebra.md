# Linear Algebra for Machine Learning

Machine learning heavily utilizes linear algebra, particularly in the areas of neural networks, dimensionality reduction, and feature extraction.

## Topics
- System of Linear Equations: A system of linear equations is a collection of two or more linear equations that must be solved simultaneously. The goal is to find the values of the variables that satisfy all the equations in the system.
- Matrix Operations: Addition, subtraction, multiplication, row/ coulmn operations, transpose, factorization, determinants, inverses
- Matrix Decomposition -  Principal Component Analysis, Singular Value Decomposition, Linear Discriminant Analysis, Non-negative Matrix Factorization, t-SNE
- Eigenvalues / Eigenvectors: Eigenvalues and eigenvectors are concepts from linear algebra that are used to understand the behavior of linear transformations and matrices.
- Vector Spaces: Vector spaces are used to represent feature spaces, where data points are represented as vectors.
- Linear Transformations: Fundamental for understanding data transformations.
- Orthogonality and Least Squares: Key in optimization problems and for understanding distances and approximations.
