3. Probability
Random Variables: Understanding the behavior and features of random phenomena.
Probability Distributions: Normal, Binomial, Poisson, etc., underpin much of machine learning.
Expectation, Variance, and Covariance: Key statistics for summarizing random variables.
Conditional Probability: Foundation of Bayesian inference.
Joint and Marginal Distributions: Important for understanding the relationships between variables.
Bayes' Theorem: Fundamental for Bayesian methods in machine learning.
Central Limit Theorem: Underpins many statistical methods and machine learning algorithms.